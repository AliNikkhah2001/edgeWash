{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Quantization-aware training (GPU)\n\nThis notebook:\n- builds a MobileNetV2 classifier with full-layer QAT\n- trains on Kaggle WHO6 using random-frame sampling from videos\n- evaluates the quantized model\n- exports an INT8 TFLite model\n\nNote: QAT expects a GPU for reasonable speed, but it also runs on CPU.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "%pip install -q numpy pandas opencv-python tensorflow tensorflow-model-optimization tqdm requests\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import os\nimport sys\nimport time\nimport random\nimport tarfile\nfrom pathlib import Path\nimport importlib.util\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport tensorflow as tf\nimport tensorflow_model_optimization as tfmot\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport requests\n\n\ndef find_repo_root(start=None):\n    start = Path.cwd() if start is None else Path(start)\n    for parent in [start] + list(start.parents):\n        if (parent / \"inference\" / \"config.py\").exists() or (parent / \"training\" / \"config.py\").exists():\n            return parent\n    return start\n\n\ndef _load_module(path: Path, name: str):\n    spec = importlib.util.spec_from_file_location(name, path)\n    if spec is None or spec.loader is None:\n        raise ImportError(f\"Cannot load module from {path}\")\n    module = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(module)\n    return module\n\n\nREPO_ROOT = find_repo_root()\nINFERENCE_DIR = REPO_ROOT / \"inference\"\nTRAINING_DIR = REPO_ROOT / \"training\"\n\nif (INFERENCE_DIR / \"config.py\").exists():\n    cfg = _load_module(INFERENCE_DIR / \"config.py\", \"cfg\")\nelif (TRAINING_DIR / \"config.py\").exists():\n    cfg = _load_module(TRAINING_DIR / \"config.py\", \"cfg\")\nelse:\n    raise FileNotFoundError(\"config.py not found in inference/ or training/\")\n\nnp.random.seed(cfg.RANDOM_SEED)\nrandom.seed(cfg.RANDOM_SEED)\ntry:\n    tf.random.set_seed(cfg.RANDOM_SEED)\nexcept Exception:\n    pass\n\nRAW_DIR = REPO_ROOT / \"datasets\" / \"raw\"\nOUTPUT_DIR = TRAINING_DIR / \"outputs\"\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"Repo root:\", REPO_ROOT)\nprint(\"Output dir:\", OUTPUT_DIR)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## GPU check\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "print(\"TF version:\", tf.__version__)\nprint(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\nfor gpu in tf.config.list_physical_devices(\"GPU\"):\n    try:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    except Exception:\n        pass\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Download Kaggle WHO6 dataset (if needed)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "KAGGLE_URL = cfg.DATASETS[\"kaggle\"][\"url\"]\nKAGGLE_DIR = RAW_DIR / \"kaggle\"\nKAGGLE_TAR = KAGGLE_DIR / \"kaggle-dataset-6classes.tar\"\nKAGGLE_EXTRACTED = KAGGLE_DIR / \"kaggle-dataset-6classes\"\n\n\ndef download_with_progress(url, dest: Path):\n    dest.parent.mkdir(parents=True, exist_ok=True)\n    if dest.exists():\n        print(\"skip\", dest)\n        return\n    with requests.get(url, stream=True, timeout=30) as r:\n        r.raise_for_status()\n        total = int(r.headers.get(\"content-length\", 0))\n        with open(dest, \"wb\") as f, tqdm(total=total, unit=\"B\", unit_scale=True, desc=dest.name) as pbar:\n            for chunk in r.iter_content(chunk_size=1024 * 1024):\n                if not chunk:\n                    continue\n                f.write(chunk)\n                pbar.update(len(chunk))\n\n\ndef extract_tar(tar_path: Path, target_dir: Path):\n    if target_dir.exists():\n        print(\"skip\", target_dir)\n        return\n    target_dir.mkdir(parents=True, exist_ok=True)\n    with tarfile.open(tar_path, \"r\") as tar:\n        tar.extractall(path=target_dir)\n\n\nif not KAGGLE_EXTRACTED.exists():\n    print(\"Downloading Kaggle WHO6...\")\n    download_with_progress(KAGGLE_URL, KAGGLE_TAR)\n    print(\"Extracting...\")\n    extract_tar(KAGGLE_TAR, KAGGLE_DIR)\nelse:\n    print(\"Kaggle dataset already extracted:\", KAGGLE_EXTRACTED)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Index videos and create splits\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "VIDEO_EXTS = (\".mp4\", \".avi\", \".mov\", \".mkv\")\n\n\ndef kaggle_class_id_from_folder(name: str) -> int:\n    name_lower = name.lower()\n    if name_lower in cfg.KAGGLE_CLASS_MAPPING:\n        return int(cfg.KAGGLE_CLASS_MAPPING[name_lower])\n    digits = \"\".join(ch for ch in name_lower if ch.isdigit())\n    if digits:\n        class_id = int(digits)\n        if 0 <= class_id < len(cfg.CLASS_NAMES):\n            return class_id\n    raise ValueError(f\"Unknown Kaggle class folder: {name}\")\n\n\ndef collect_videos(dataset_root: Path) -> pd.DataFrame:\n    rows = []\n    for class_dir in sorted(dataset_root.iterdir()):\n        if not class_dir.is_dir():\n            continue\n        class_id = kaggle_class_id_from_folder(class_dir.name)\n        for vid in class_dir.iterdir():\n            if vid.suffix.lower() not in VIDEO_EXTS:\n                continue\n            rows.append({\"video_path\": str(vid), \"class_id\": class_id})\n    df = pd.DataFrame(rows)\n    if df.empty:\n        raise RuntimeError(f\"No videos found in {dataset_root}\")\n    return df\n\n\nvideos_df = collect_videos(KAGGLE_EXTRACTED)\nprint(\"Total videos:\", len(videos_df))\n\ntrain_df, temp_df = train_test_split(\n    videos_df,\n    test_size=(cfg.VAL_RATIO + cfg.TEST_RATIO),\n    stratify=videos_df[\"class_id\"],\n    random_state=cfg.RANDOM_SEED,\n)\nval_size = cfg.VAL_RATIO / (cfg.VAL_RATIO + cfg.TEST_RATIO)\nval_df, test_df = train_test_split(\n    temp_df,\n    test_size=(1.0 - val_size),\n    stratify=temp_df[\"class_id\"],\n    random_state=cfg.RANDOM_SEED,\n)\n\nprint(\"Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## tf.data pipeline (random frames per video)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_v2_preprocess\n\nIMG_SIZE = cfg.IMG_SIZE\nNUM_CLASSES = cfg.NUM_CLASSES\n\n\ndef _load_random_frame_py(video_path_bytes, label):\n    video_path = video_path_bytes.decode(\"utf-8\")\n    cap = cv2.VideoCapture(video_path)\n    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    if frame_count <= 0:\n        cap.release()\n        raise RuntimeError(f\"No frames in {video_path}\")\n    target_idx = np.random.randint(0, frame_count)\n    cap.set(cv2.CAP_PROP_POS_FRAMES, target_idx)\n    ok, frame = cap.read()\n    cap.release()\n    if not ok:\n        raise RuntimeError(f\"Failed reading frame from {video_path}\")\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    frame = cv2.resize(frame, IMG_SIZE)\n    frame = frame.astype(np.float32)\n    frame = mobilenet_v2_preprocess(frame)\n    return frame, np.int32(label)\n\n\ndef _load_random_frame(video_path, label):\n    frame, label = tf.py_function(\n        _load_random_frame_py,\n        inp=[video_path, label],\n        Tout=[tf.float32, tf.int32],\n    )\n    frame.set_shape((*IMG_SIZE, 3))\n    label.set_shape(())\n    return frame, label\n\n\ndef make_dataset(df, batch_size=32, shuffle=True):\n    ds = tf.data.Dataset.from_tensor_slices((df[\"video_path\"].values, df[\"class_id\"].values))\n    if shuffle:\n        ds = ds.shuffle(len(df), seed=cfg.RANDOM_SEED, reshuffle_each_iteration=True)\n    ds = ds.map(_load_random_frame, num_parallel_calls=tf.data.AUTOTUNE)\n    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return ds\n\n\nBATCH_SIZE = 32\ntrain_ds = make_dataset(train_df, batch_size=BATCH_SIZE, shuffle=True)\nval_ds = make_dataset(val_df, batch_size=BATCH_SIZE, shuffle=False)\ntest_ds = make_dataset(test_df, batch_size=BATCH_SIZE, shuffle=False)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Build MobileNetV2 + QAT\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from tensorflow.keras import layers, models\n\n\ndef build_model():\n    base = tf.keras.applications.MobileNetV2(\n        input_shape=(*IMG_SIZE, 3),\n        include_top=False,\n        weights=None,\n    )\n    base.trainable = True\n    inputs = layers.Input(shape=(*IMG_SIZE, 3))\n    x = base(inputs, training=True)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.3)(x)\n    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n    model = models.Model(inputs, outputs)\n    return model\n\n\nfloat_model = build_model()\nquantize_model = tfmot.quantization.keras.quantize_model\nqat_model = quantize_model(float_model)\n\nqat_model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    metrics=[\"accuracy\"],\n)\n\nqat_model.summary()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Train\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "EPOCHS = 5\n\nhistory = qat_model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS,\n)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Evaluate\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "qat_eval = qat_model.evaluate(test_ds, verbose=1)\nprint(\"QAT test metrics:\", dict(zip(qat_model.metrics_names, qat_eval)))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Save QAT model and export INT8 TFLite\n\nAxis DLPU devices require INT8 TFLite with built-in ops.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from typing import Iterable\n\nqat_model_path = OUTPUT_DIR / \"mobilenetv2_qat.keras\"\nqat_model.save(qat_model_path)\nprint(\"Saved QAT model:\", qat_model_path)\n\nDISABLE_PER_CHANNEL = False\n\n\ndef representative_dataset_from_ds(ds, max_batches=10) -> Iterable[list[np.ndarray]]:\n    count = 0\n    for batch, _ in ds:\n        batch_np = batch.numpy().astype(np.float32)\n        for i in range(batch_np.shape[0]):\n            yield [batch_np[i : i + 1]]\n        count += 1\n        if count >= max_batches:\n            break\n\n\ntflite_path = OUTPUT_DIR / \"mobilenetv2_qat_int8.tflite\"\nconverter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = lambda: representative_dataset_from_ds(train_ds)\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\nconverter.inference_input_type = tf.int8\nconverter.inference_output_type = tf.int8\nif DISABLE_PER_CHANNEL:\n    converter._experimental_disable_per_channel = True\n\ntry:\n    tflite_model = converter.convert()\n    tflite_path.write_bytes(tflite_model)\n    print(\"Saved TFLite:\", tflite_path)\nexcept Exception as exc:\n    print(\"INT8 conversion failed:\", exc)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "if tflite_path.exists():\n    interpreter = tf.lite.Interpreter(model_path=str(tflite_path))\n    interpreter.allocate_tensors()\n    input_detail = interpreter.get_input_details()[0]\n    output_detail = interpreter.get_output_details()[0]\n    print(\"Input dtype:\", input_detail[\"dtype\"], \"quant:\", input_detail.get(\"quantization\"))\n    print(\"Output dtype:\", output_detail[\"dtype\"], \"quant:\", output_detail.get(\"quantization\"))\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}