{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwash Dataset Validation Notebook\n",
    "\n",
    "This notebook downloads and validates all four datasets (kaggle, pskus, metc, synthetic_blender_rozakar).\n",
    "It provides exploratory analysis, shows sample videos and frames for each class, and reports mapped classes after preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q --no-cache-dir scikit-learn pandas numpy opencv-python-headless matplotlib seaborn tqdm requests gdown zenodo-get ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, json, math, random, shutil, subprocess, re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Video, display\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "DATA_ROOT = Path(os.environ.get(\"HANDWASH_DATA\", \"/kaggle/working/handwash_data\"))\n",
    "RAW_DIR = DATA_ROOT / \"raw\"\n",
    "PROCESSED_DIR = DATA_ROOT / \"processed\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATASETS = [\"kaggle\", \"pskus\", \"metc\", \"synthetic_blender_rozakar\"]\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "NUM_CLASSES = 7\n",
    "CLASS_NAMES = [\n",
    "    \"Other\",\n",
    "    \"Step1_PalmToPalm\",\n",
    "    \"Step2_PalmOverDorsum\",\n",
    "    \"Step3_InterlacedFingers\",\n",
    "    \"Step4_BackOfFingers\",\n",
    "    \"Step5_ThumbRub\",\n",
    "    \"Step6_Fingertips\",\n",
    "]\n",
    "\n",
    "PSKUS_CODE_MAPPING = {\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 3,\n",
    "    4: 4,\n",
    "    5: 5,\n",
    "    6: 6,\n",
    "    7: 0,\n",
    "}\n",
    "\n",
    "METC_CODE_MAPPING = {\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 3,\n",
    "    4: 4,\n",
    "    5: 5,\n",
    "    6: 6,\n",
    "}\n",
    "\n",
    "LABEL_TOKENS = {\n",
    "    \"step1\": 1,\n",
    "    \"step2\": 2,\n",
    "    \"step3\": 3,\n",
    "    \"step4\": 4,\n",
    "    \"step5\": 5,\n",
    "    \"step6\": 6,\n",
    "    \"other\": 0,\n",
    "}\n",
    "\n",
    "SYNTHETIC_GESTURE_TO_CLASS = {\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 2,\n",
    "    4: 3,\n",
    "    5: 4,\n",
    "    6: 5,\n",
    "    7: 5,\n",
    "    8: 6,\n",
    "}\n",
    "\n",
    "VIDEO_EXTS = (\".mp4\", \".avi\", \".mov\", \".mkv\")\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "FRAME_SKIP = 2\n",
    "MAX_VIDEOS_PER_DATASET = None  # set to int to limit processing\n",
    "MAX_FRAMES_PER_VIDEO = None  # set to int to limit per-video frame extraction\n",
    "\n",
    "KAGGLE_URL = \"https://github.com/atiselsts/data/raw/master/kaggle-dataset-6classes.tar\"\n",
    "PSKUS_ZENODO = \"4537209\"\n",
    "METC_ZENODO = \"5808789\"\n",
    "SYNTHETIC_LINKS = [\n",
    "    \"https://drive.google.com/uc?id=1EW3JQvElcuXzawxEMRkA8YXwK_Ipiv-p&export=download\",\n",
    "    \"https://drive.google.com/uc?id=163TsrDe4q5KTQGCv90JRYFkCs7AGxFip&export=download\",\n",
    "    \"https://drive.google.com/uc?id=1GxyTYfSodumH78NbjWdmbjm8JP8AOkAY&export=download\",\n",
    "    \"https://drive.google.com/uc?id=1IoRsgBBr8qoC3HO-vEr6E7K4UZ6ku6-1&export=download\",\n",
    "    \"https://drive.google.com/uc?id=1svCYnwDazy5FN1DYSgqbGscvDKL_YnID&export=download\",\n",
    "]\n",
    "# Partial download controls (None = download all)\n",
    "PSKUS_DATASET_IDS = None  # e.g. [1, 2] to fetch subset of DataSet*.zip\n",
    "METC_INTERFACE_IDS = None  # e.g. [1] to fetch subset of Interface_number_*.zip\n",
    "SYNTHETIC_MAX_ZIPS = None  # e.g. 1 to limit number of synthetic zips\n",
    "DOWNLOAD_PSKUS_SPLIT_CSV = True\n",
    "DOWNLOAD_METC_CSV = True\n",
    "\n",
    "LOG_DIR = DATA_ROOT / \"logs\" / \"validation\"\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_SAMPLE_VIDEOS = 2\n",
    "SAMPLES_PER_CLASS = 3\n",
    "SAMPLE_VIDEO_FRAMES = 24\n",
    "SAMPLE_VIDEO_FPS = 6\n",
    "\n",
    "SAVE_LOGS = True\n",
    "SAVE_SAMPLE_MEDIA = True\n",
    "CALCULATE_DISK_USAGE = True\n",
    "CLEANUP_BETWEEN_DATASETS = True\n",
    "CLEANUP_ON_FAILURE = False\n",
    "CLEANUP_ARCHIVES = True\n",
    "\n",
    "ALL_MAPPINGS = []\n",
    "\n",
    "\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_with_progress(url: str, dest: Path):\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dest.exists():\n",
    "        print(\"skip\", dest)\n",
    "        return\n",
    "    import requests\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total = int(r.headers.get(\"content-length\", 0))\n",
    "        with open(dest, \"wb\") as f, tqdm(total=total, unit=\"B\", unit_scale=True, desc=dest.name) as pbar:\n",
    "            for chunk in r.iter_content(chunk_size=1024 * 1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "\n",
    "\n",
    "def extract_tar(tar_path: Path, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    import tarfile\n",
    "    with tarfile.open(tar_path) as tfp:\n",
    "        tfp.extractall(out_dir)\n",
    "    tar_path.unlink(missing_ok=True)\n",
    "\n",
    "\n",
    "def extract_zip(zip_path: Path, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(zip_path) as zf:\n",
    "        zf.extractall(out_dir)\n",
    "    zip_path.unlink(missing_ok=True)\n",
    "\n",
    "\n",
    "def _extract_archives_if_needed(raw_dir: Path):\n",
    "    zip_files = sorted(raw_dir.glob(\"*.zip\"))\n",
    "    tar_files = sorted(raw_dir.glob(\"*.tar*\"))\n",
    "    if zip_files or tar_files:\n",
    "        print(\"Extracting existing archives in\", raw_dir)\n",
    "    for zip_file in zip_files:\n",
    "        extract_zip(zip_file, raw_dir)\n",
    "    for tar_file in tar_files:\n",
    "        extract_tar(tar_file, raw_dir)\n",
    "\n",
    "\n",
    "def download_kaggle():\n",
    "    out_dir = RAW_DIR / \"kaggle\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tar_path = out_dir / \"kaggle-dataset-6classes.tar\"\n",
    "    download_with_progress(KAGGLE_URL, tar_path)\n",
    "    print(\"Extracting kaggle...\")\n",
    "    extract_tar(tar_path, out_dir)\n",
    "    return out_dir\n",
    "\n",
    "\n",
    "def _zenodo_file_url(record_id: str, filename: str) -> str:\n",
    "    return f\"https://zenodo.org/record/{record_id}/files/{filename}?download=1\"\n",
    "\n",
    "\n",
    "def download_zenodo(zenodo_id: str, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cmd = [\"zenodo_get\", \"-r\", zenodo_id, \"-o\", str(out_dir)]\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "    zip_files = sorted(out_dir.glob(\"*.zip\"))\n",
    "    tar_files = sorted(out_dir.glob(\"*.tar*\"))\n",
    "    if zip_files or tar_files:\n",
    "        print(\"Extracting Zenodo archives...\")\n",
    "    for zip_file in zip_files:\n",
    "        extract_zip(zip_file, out_dir)\n",
    "    for tar_file in tar_files:\n",
    "        extract_tar(tar_file, out_dir)\n",
    "    return out_dir\n",
    "\n",
    "\n",
    "def download_pskus():\n",
    "    out_dir = RAW_DIR / \"pskus\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if PSKUS_DATASET_IDS is None:\n",
    "        return download_zenodo(PSKUS_ZENODO, out_dir)\n",
    "    for ds_id in PSKUS_DATASET_IDS:\n",
    "        filename = f\"DataSet{ds_id}.zip\"\n",
    "        download_with_progress(_zenodo_file_url(PSKUS_ZENODO, filename), out_dir / filename)\n",
    "        extract_zip(out_dir / filename, out_dir)\n",
    "    if DOWNLOAD_PSKUS_SPLIT_CSV:\n",
    "        csv_name = \"statistics-with-locations.csv\"\n",
    "        download_with_progress(_zenodo_file_url(PSKUS_ZENODO, csv_name), out_dir / csv_name)\n",
    "    return out_dir\n",
    "\n",
    "def download_metc():\n",
    "    out_dir = RAW_DIR / \"metc\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if METC_INTERFACE_IDS is None:\n",
    "        return download_zenodo(METC_ZENODO, out_dir)\n",
    "    for interface_id in METC_INTERFACE_IDS:\n",
    "        filename = f\"Interface_number_{interface_id}.zip\"\n",
    "        download_with_progress(_zenodo_file_url(METC_ZENODO, filename), out_dir / filename)\n",
    "        extract_zip(out_dir / filename, out_dir)\n",
    "    if DOWNLOAD_METC_CSV:\n",
    "        for csv_name in (\"summary.csv\", \"statistics.csv\"):\n",
    "            download_with_progress(_zenodo_file_url(METC_ZENODO, csv_name), out_dir / csv_name)\n",
    "    return out_dir\n",
    "\n",
    "def download_synthetic():\n",
    "    out_dir = RAW_DIR / \"synthetic_blender_rozakar\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    links = SYNTHETIC_LINKS\n",
    "    if SYNTHETIC_MAX_ZIPS is not None:\n",
    "        links = SYNTHETIC_LINKS[:SYNTHETIC_MAX_ZIPS]\n",
    "    for i, link in enumerate(links, 1):\n",
    "        out_zip = out_dir / f\"synth_{i}.zip\"\n",
    "        if not out_zip.exists():\n",
    "            subprocess.check_call([\"gdown\", \"-q\", link, \"-O\", str(out_zip)])\n",
    "        extract_zip(out_zip, out_dir)\n",
    "    return out_dir\n",
    "\n",
    "def ensure_dataset(name: str):\n",
    "    raw_dir = RAW_DIR / name\n",
    "    if raw_dir.exists():\n",
    "        _extract_archives_if_needed(raw_dir)\n",
    "        print(\"Using existing raw data\", raw_dir)\n",
    "        return raw_dir\n",
    "    if name == \"kaggle\":\n",
    "        return download_kaggle()\n",
    "    if name == \"pskus\":\n",
    "        return download_pskus()\n",
    "    if name == \"metc\":\n",
    "        return download_metc()\n",
    "    if name == \"synthetic_blender_rozakar\":\n",
    "        return download_synthetic()\n",
    "    raise ValueError(\"Unknown dataset \" + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infer_label_from_path(p: Path) -> int:\n",
    "    parts = [part for part in Path(p).parts]\n",
    "    for part in reversed(parts):\n",
    "        if part.isdigit():\n",
    "            class_id = int(part)\n",
    "            if 0 <= class_id < len(CLASS_NAMES):\n",
    "                return class_id\n",
    "    text = str(p).lower()\n",
    "    for token, idx in LABEL_TOKENS.items():\n",
    "        if token in text:\n",
    "            return idx\n",
    "    return 0\n",
    "\n",
    "\n",
    "def _parse_int_from_text(text: str) -> int | None:\n",
    "    match = re.search(r\"(\\d+)\", text)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "\n",
    "def infer_synthetic_class_id(path: Path) -> int | None:\n",
    "    for part in path.parts:\n",
    "        if \"gesture\" in part.lower():\n",
    "            num = _parse_int_from_text(part)\n",
    "            if num is None:\n",
    "                continue\n",
    "            return SYNTHETIC_GESTURE_TO_CLASS.get(num)\n",
    "    return None\n",
    "\n",
    "\n",
    "def synthetic_video_id(path: Path) -> str:\n",
    "    parts = list(path.parts)\n",
    "    gesture_idx = None\n",
    "    for i, part in enumerate(parts):\n",
    "        if part.lower().startswith(\"gesture\"):\n",
    "            gesture_idx = i\n",
    "    if gesture_idx is None or gesture_idx < 2:\n",
    "        return path.stem\n",
    "    character = parts[gesture_idx - 2]\n",
    "    environment = parts[gesture_idx - 1]\n",
    "    gesture = parts[gesture_idx]\n",
    "    return f\"{character}_{environment}_{gesture}\"\n",
    "\n",
    "\n",
    "def parse_frame_idx(path: Path) -> int:\n",
    "    num = _parse_int_from_text(path.stem)\n",
    "    return int(num) if num is not None else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _majority_vote(labels, total_movements):\n",
    "    counts = [0] * total_movements\n",
    "    for el in labels:\n",
    "        counts[int(el)] += 1\n",
    "    best = 0\n",
    "    for i in range(1, total_movements):\n",
    "        if counts[best] < counts[i]:\n",
    "            best = i\n",
    "    majority = (len(labels) + 2) // 2\n",
    "    if counts[best] < majority:\n",
    "        return -1\n",
    "    return best\n",
    "\n",
    "\n",
    "def _discount_reaction_indeterminacy(labels, reaction_frames):\n",
    "    new_labels = [u for u in labels]\n",
    "    n = len(labels) - 1\n",
    "    for i in range(n):\n",
    "        if i == 0 or labels[i] != labels[i + 1] or i == n - 1:\n",
    "            start = max(0, i - reaction_frames)\n",
    "            end = i\n",
    "            for j in range(start, end):\n",
    "                new_labels[j] = -1\n",
    "            start = i\n",
    "            end = min(n + 1, i + reaction_frames)\n",
    "            for j in range(start, end):\n",
    "                new_labels[j] = -1\n",
    "    return new_labels\n",
    "\n",
    "\n",
    "def _select_frames_to_save(is_washing, codes, movement0_prop=1.0):\n",
    "    old_code = -1\n",
    "    old_saved = False\n",
    "    num_snippets = 0\n",
    "    mapping = {}\n",
    "    current_snippet = {}\n",
    "    for i in range(len(is_washing)):\n",
    "        new_code = codes[i]\n",
    "        new_saved = (is_washing[i] == 2 and new_code != -1)\n",
    "        if new_saved != old_saved:\n",
    "            if new_saved:\n",
    "                num_snippets += 1\n",
    "                current_snippet = {}\n",
    "            else:\n",
    "                if old_code != 0 or np.random.rand() < movement0_prop:\n",
    "                    for key in current_snippet:\n",
    "                        mapping[key] = current_snippet[key]\n",
    "        if new_saved:\n",
    "            current_snippet_frame = len(current_snippet)\n",
    "            current_snippet[i] = (current_snippet_frame, num_snippets, new_code)\n",
    "        old_saved = new_saved\n",
    "        old_code = new_code\n",
    "    if old_saved:\n",
    "        if old_code != 0 or np.random.rand() < movement0_prop:\n",
    "            for key in current_snippet:\n",
    "                mapping[key] = current_snippet[key]\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def _find_annotations_dir(video_path: Path) -> Path | None:\n",
    "    for parent in video_path.parents:\n",
    "        ann_dir = parent / \"Annotations\"\n",
    "        if ann_dir.exists():\n",
    "            return ann_dir\n",
    "    return None\n",
    "\n",
    "\n",
    "def _load_frame_annotations(video_path: Path, annotator_prefix: str, total_annotators: int):\n",
    "    ann_dir = _find_annotations_dir(video_path)\n",
    "    if not ann_dir:\n",
    "        return [], 0\n",
    "    annotations = []\n",
    "    for a in range(1, total_annotators + 1):\n",
    "        annotator_dir = ann_dir / f\"{annotator_prefix}{a}\"\n",
    "        json_path = annotator_dir / f\"{video_path.stem}.json\"\n",
    "        if not json_path.exists():\n",
    "            continue\n",
    "        try:\n",
    "            with open(json_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            a_annotations = [(data['labels'][i]['is_washing'], data['labels'][i]['code']) for i in range(len(data['labels']))]\n",
    "            annotations.append(a_annotations)\n",
    "        except Exception as exc:\n",
    "            print(\"Failed to load\", json_path, exc)\n",
    "    return annotations, len(annotations)\n",
    "\n",
    "\n",
    "def _frame_labels_from_annotations(annotations, total_movements, reaction_frames, code_mapping=None):\n",
    "    num_annotators = len(annotations)\n",
    "    if num_annotators == 0:\n",
    "        return [], []\n",
    "    if code_mapping is None:\n",
    "        code_mapping = {i: i for i in range(total_movements)}\n",
    "    num_frames = len(annotations[0])\n",
    "    is_washing, codes = [], []\n",
    "    for frame_num in range(num_frames):\n",
    "        frame_annotations = [annotations[a][frame_num] for a in range(num_annotators)]\n",
    "        frame_is_washing_any = any(frame_annotations[a][0] for a in range(num_annotators))\n",
    "        frame_is_washing_all = all(frame_annotations[a][0] for a in range(num_annotators))\n",
    "        frame_codes = [frame_annotations[a][1] for a in range(num_annotators)]\n",
    "        frame_codes = [code_mapping.get(int(code), 0) for code in frame_codes]\n",
    "        if frame_is_washing_all:\n",
    "            frame_is_washing = 2\n",
    "        elif frame_is_washing_any:\n",
    "            frame_is_washing = 1\n",
    "        else:\n",
    "            frame_is_washing = 0\n",
    "        is_washing.append(frame_is_washing)\n",
    "        if frame_is_washing:\n",
    "            codes.append(_majority_vote(frame_codes, total_movements))\n",
    "        else:\n",
    "            codes.append(-1)\n",
    "    is_washing = _discount_reaction_indeterminacy(is_washing, reaction_frames)\n",
    "    codes = _discount_reaction_indeterminacy(codes, reaction_frames)\n",
    "    return is_washing, codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _find_pskus_split_csv(raw_dir: Path):\n",
    "    csv_path = raw_dir / \"statistics-with-locations.csv\"\n",
    "    if csv_path.exists():\n",
    "        return csv_path\n",
    "    candidates = [\n",
    "        Path.cwd() / \"code/edgewash/dataset-pskus/statistics-with-locations.csv\",\n",
    "        Path.cwd() / \"edgeWash/code/edgewash/dataset-pskus/statistics-with-locations.csv\",\n",
    "    ]\n",
    "    for candidate in candidates:\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    return None\n",
    "\n",
    "\n",
    "def _load_pskus_split(pskus_dir: Path):\n",
    "    csv_path = pskus_dir / \"statistics-with-locations.csv\"\n",
    "    if not csv_path.exists():\n",
    "        fallback = _find_pskus_split_csv(pskus_dir)\n",
    "        if fallback is not None:\n",
    "            csv_path = fallback\n",
    "            print(\"Using fallback PSKUS split file:\", csv_path)\n",
    "    if not csv_path.exists():\n",
    "        print(\"PSKUS split CSV not found; will use random split later\")\n",
    "        return set(), set()\n",
    "    testfiles, trainvalfiles = set(), set()\n",
    "    try:\n",
    "        import csv as csv_lib\n",
    "        with open(csv_path, \"r\") as csv_file:\n",
    "            reader = csv_lib.reader(csv_file)\n",
    "            for row in reader:\n",
    "                if row and row[0] == \"filename\":\n",
    "                    continue\n",
    "                if not row:\n",
    "                    continue\n",
    "                filename = row[0]\n",
    "                location = row[1] if len(row) > 1 else \"\"\n",
    "                if location == \"Reanim\\u0101cija\":\n",
    "                    testfiles.add(filename)\n",
    "                elif location != \"unknown\":\n",
    "                    trainvalfiles.add(filename)\n",
    "    except Exception as exc:\n",
    "        print(\"Failed to read PSKUS split CSV\", csv_path, exc)\n",
    "    return testfiles, trainvalfiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_frames_from_video(video_path: Path, out_dir: Path, frame_skip: int) -> List[Dict]:\n",
    "    rows = []\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        return rows\n",
    "    base = video_path.stem\n",
    "    label = infer_label_from_path(video_path)\n",
    "    idx = 0\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_idx % frame_skip == 0:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, IMG_SIZE)\n",
    "            out_path = out_dir / f\"{base}_{idx:06d}.jpg\"\n",
    "            cv2.imwrite(str(out_path), frame[:, :, ::-1])\n",
    "            rows.append({\"frame_path\": str(out_path), \"class_id\": label, \"video_id\": base, \"frame_idx\": idx})\n",
    "            idx += 1\n",
    "            if MAX_FRAMES_PER_VIDEO is not None and idx >= MAX_FRAMES_PER_VIDEO:\n",
    "                break\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "    return rows\n",
    "\n",
    "\n",
    "def preprocess_images(image_paths: List[Path], out_dir: Path) -> List[Dict]:\n",
    "    rows = []\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for img_path in tqdm(image_paths, desc=\"images\"):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        label = infer_label_from_path(img_path)\n",
    "        out_path = out_dir / f\"{img_path.stem}.jpg\"\n",
    "        cv2.imwrite(str(out_path), img[:, :, ::-1])\n",
    "        rows.append({\"frame_path\": str(out_path), \"class_id\": label, \"video_id\": img_path.parent.name, \"frame_idx\": 0})\n",
    "    return rows\n",
    "\n",
    "\n",
    "def _split_train_val_by_video(df, train_ratio=0.7, val_ratio=0.15):\n",
    "    unique_videos = df[\"video_id\"].unique()\n",
    "    video_to_class = df.groupby(\"video_id\")[\"class_id\"].first()\n",
    "    val_size = val_ratio / (train_ratio + val_ratio)\n",
    "    train_videos, val_videos = train_test_split(\n",
    "        unique_videos,\n",
    "        test_size=val_size,\n",
    "        random_state=42,\n",
    "        stratify=video_to_class[unique_videos],\n",
    "    )\n",
    "    train_df = df[df[\"video_id\"].isin(train_videos)].reset_index(drop=True)\n",
    "    val_df = df[df[\"video_id\"].isin(val_videos)].reset_index(drop=True)\n",
    "    return train_df, val_df\n",
    "\n",
    "\n",
    "def split_and_save(df: pd.DataFrame, out_dir: Path) -> Dict[str, Path]:\n",
    "    if \"split\" in df.columns and df[\"split\"].notna().any():\n",
    "        test_df = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "        trainval_df = df[df[\"split\"] != \"test\"].reset_index(drop=True)\n",
    "        if not trainval_df.empty:\n",
    "            train_df, val_df = _split_train_val_by_video(trainval_df)\n",
    "        else:\n",
    "            train_df, val_df = df, df.iloc[0:0].copy()\n",
    "    else:\n",
    "        df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        n = len(df)\n",
    "        train_end = int(0.7 * n)\n",
    "        val_end = int(0.85 * n)\n",
    "        train_df, val_df, test_df = df.iloc[:train_end], df.iloc[train_end:val_end], df.iloc[val_end:]\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    train_csv = out_dir / \"train.csv\"\n",
    "    val_csv = out_dir / \"val.csv\"\n",
    "    test_csv = out_dir / \"test.csv\"\n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    val_df.to_csv(val_csv, index=False)\n",
    "    test_df.to_csv(test_csv, index=False)\n",
    "    return {\"train\": train_csv, \"val\": val_csv, \"test\": test_csv}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_pskus_dataset(pskus_dir: Path, frames_root: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    testfiles, trainvalfiles = _load_pskus_split(pskus_dir)\n",
    "    has_split = bool(testfiles or trainvalfiles)\n",
    "    movement0_prop = 0.2\n",
    "    total_annotators = 8\n",
    "    total_movements = 8\n",
    "    fps = 30\n",
    "    reaction_frames = fps // 2\n",
    "\n",
    "    for video_path in pskus_dir.rglob(\"*.mp4\"):\n",
    "        filename = video_path.name\n",
    "        if has_split:\n",
    "            if filename in testfiles:\n",
    "                split = \"test\"\n",
    "            elif filename in trainvalfiles:\n",
    "                split = \"trainval\"\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            split = None\n",
    "\n",
    "        annotations, num_annotators = _load_frame_annotations(video_path, \"Annotator\", total_annotators)\n",
    "        if num_annotators <= 1:\n",
    "            continue\n",
    "        is_washing, codes = _frame_labels_from_annotations(\n",
    "            annotations, total_movements, reaction_frames, code_mapping=PSKUS_CODE_MAPPING\n",
    "        )\n",
    "        mapping = _select_frames_to_save(is_washing, codes, movement0_prop)\n",
    "        if not mapping:\n",
    "            continue\n",
    "        frames_dir = frames_root / (split or \"trainval\")\n",
    "        vidcap = cv2.VideoCapture(str(video_path))\n",
    "        is_success, image = vidcap.read()\n",
    "        frame_number = 0\n",
    "        saved = 0\n",
    "        while is_success:\n",
    "            if frame_number in mapping:\n",
    "                new_frame_num, snippet_num, code = mapping[frame_number]\n",
    "                out_sub = frames_dir / str(code)\n",
    "                out_sub.mkdir(parents=True, exist_ok=True)\n",
    "                filename_out = f\"frame_{new_frame_num}_snippet_{snippet_num}_{video_path.stem}.jpg\"\n",
    "                save_path = out_sub / filename_out\n",
    "                image_resized = cv2.resize(image, IMG_SIZE)\n",
    "                cv2.imwrite(str(save_path), image_resized)\n",
    "                row = {\n",
    "                    \"frame_path\": str(save_path),\n",
    "                    \"class_id\": int(code),\n",
    "                    \"video_id\": video_path.stem,\n",
    "                    \"frame_idx\": new_frame_num,\n",
    "                }\n",
    "                if split:\n",
    "                    row[\"split\"] = split\n",
    "                rows.append(row)\n",
    "                saved += 1\n",
    "                if MAX_FRAMES_PER_VIDEO is not None and saved >= MAX_FRAMES_PER_VIDEO:\n",
    "                    break\n",
    "            is_success, image = vidcap.read()\n",
    "            frame_number += 1\n",
    "        vidcap.release()\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def preprocess_metc_dataset(metc_dir: Path, frames_root: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    total_annotators = 1\n",
    "    total_movements = 7\n",
    "    fps = 16\n",
    "    reaction_frames = fps // 2\n",
    "    test_proportion = 0.25\n",
    "    for video_path in metc_dir.rglob(\"*.mp4\"):\n",
    "        split = \"test\" if np.random.rand() < test_proportion else \"trainval\"\n",
    "        annotations, num_annotators = _load_frame_annotations(video_path, \"Annotator_\", total_annotators)\n",
    "        if num_annotators == 0:\n",
    "            continue\n",
    "        is_washing, codes = _frame_labels_from_annotations(\n",
    "            annotations, total_movements, reaction_frames, code_mapping=METC_CODE_MAPPING\n",
    "        )\n",
    "        mapping = _select_frames_to_save(is_washing, codes, movement0_prop=1.0)\n",
    "        if not mapping:\n",
    "            continue\n",
    "        frames_dir = frames_root / split\n",
    "        vidcap = cv2.VideoCapture(str(video_path))\n",
    "        is_success, image = vidcap.read()\n",
    "        frame_number = 0\n",
    "        saved = 0\n",
    "        while is_success:\n",
    "            if frame_number in mapping:\n",
    "                new_frame_num, snippet_num, code = mapping[frame_number]\n",
    "                out_sub = frames_dir / str(code)\n",
    "                out_sub.mkdir(parents=True, exist_ok=True)\n",
    "                filename_out = f\"frame_{new_frame_num}_snippet_{snippet_num}_{video_path.stem}.jpg\"\n",
    "                save_path = out_sub / filename_out\n",
    "                image_resized = cv2.resize(image, IMG_SIZE)\n",
    "                cv2.imwrite(str(save_path), image_resized)\n",
    "                rows.append({\n",
    "                    \"frame_path\": str(save_path),\n",
    "                    \"class_id\": int(code),\n",
    "                    \"video_id\": video_path.stem,\n",
    "                    \"frame_idx\": new_frame_num,\n",
    "                    \"split\": split,\n",
    "                })\n",
    "                saved += 1\n",
    "                if MAX_FRAMES_PER_VIDEO is not None and saved >= MAX_FRAMES_PER_VIDEO:\n",
    "                    break\n",
    "            is_success, image = vidcap.read()\n",
    "            frame_number += 1\n",
    "        vidcap.release()\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def preprocess_synthetic_dataset(raw_dir: Path, frames_root: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    frames_root.mkdir(parents=True, exist_ok=True)\n",
    "    image_paths = [p for p in raw_dir.rglob(\"*.png\") if p.is_file()]\n",
    "    for img_path in tqdm(image_paths, desc=\"synthetic\"):\n",
    "        if \"rgb\" not in [part.lower() for part in img_path.parts]:\n",
    "            continue\n",
    "        class_id = infer_synthetic_class_id(img_path)\n",
    "        if class_id is None:\n",
    "            continue\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        video_id = synthetic_video_id(img_path)\n",
    "        frame_idx = parse_frame_idx(img_path)\n",
    "        out_sub = frames_root / str(class_id)\n",
    "        out_sub.mkdir(parents=True, exist_ok=True)\n",
    "        out_path = out_sub / f\"{video_id}_{frame_idx:06d}.jpg\"\n",
    "        cv2.imwrite(str(out_path), img[:, :, ::-1])\n",
    "        rows.append({\n",
    "            \"frame_path\": str(out_path),\n",
    "            \"class_id\": int(class_id),\n",
    "            \"video_id\": video_id,\n",
    "            \"frame_idx\": int(frame_idx),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def preprocess_dataset(name: str) -> Path:\n",
    "    raw_dir = RAW_DIR / name\n",
    "    out_dir = PROCESSED_DIR / name\n",
    "    frames_dir = out_dir / \"frames\"\n",
    "    frames_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if name == \"pskus\":\n",
    "        df = preprocess_pskus_dataset(raw_dir, frames_dir)\n",
    "    elif name == \"metc\":\n",
    "        df = preprocess_metc_dataset(raw_dir, frames_dir)\n",
    "    elif name == \"synthetic_blender_rozakar\":\n",
    "        df = preprocess_synthetic_dataset(raw_dir, frames_dir)\n",
    "    else:\n",
    "        video_files = [p for p in raw_dir.rglob(\"*\") if p.suffix.lower() in VIDEO_EXTS]\n",
    "        image_files = [p for p in raw_dir.rglob(\"*\") if p.suffix.lower() in IMAGE_EXTS]\n",
    "        rows = []\n",
    "        if video_files:\n",
    "            if MAX_VIDEOS_PER_DATASET is not None:\n",
    "                video_files = video_files[:MAX_VIDEOS_PER_DATASET]\n",
    "            for vp in tqdm(video_files, desc=\"videos\"):\n",
    "                rows.extend(extract_frames_from_video(vp, frames_dir, FRAME_SKIP))\n",
    "        elif image_files:\n",
    "            rows.extend(preprocess_images(image_files, frames_dir))\n",
    "        else:\n",
    "            raise RuntimeError(\"No video or image files found in \" + str(raw_dir))\n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "    if df.empty:\n",
    "        raise RuntimeError(\"No frames extracted for \" + name)\n",
    "    split_and_save(df, out_dir)\n",
    "    return out_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _is_archive(path: Path) -> bool:\n",
    "    name = path.name.lower()\n",
    "    return name.endswith((\".zip\", \".tar\", \".tar.gz\", \".tgz\", \".tar.bz2\", \".tar.xz\"))\n",
    "\n",
    "\n",
    "def _collect_archives(root: Path, max_hits: int = 5):\n",
    "    hits = []\n",
    "    if not root.exists():\n",
    "        return hits\n",
    "    for path in root.rglob(\"*\"):\n",
    "        if path.is_file() and _is_archive(path):\n",
    "            hits.append(path)\n",
    "            if len(hits) >= max_hits:\n",
    "                break\n",
    "    return hits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cleanup_archives(root: Path, log_fp=None):\n",
    "    archives = []\n",
    "    if root.exists():\n",
    "        for path in root.rglob(\"*\"):\n",
    "            if path.is_file() and _is_archive(path):\n",
    "                archives.append(path)\n",
    "    if not archives:\n",
    "        return\n",
    "    for path in archives:\n",
    "        try:\n",
    "            path.unlink()\n",
    "        except Exception:\n",
    "            pass\n",
    "    try:\n",
    "        _log_line(log_fp, f\"Removed {len(archives)} archive files from {root}\")\n",
    "    except Exception:\n",
    "        print(f\"Removed {len(archives)} archive files from {root}\")\n",
    "\n",
    "def _iter_files(root: Path, exts, max_hits: int = 3):\n",
    "    hits = []\n",
    "    if not root.exists():\n",
    "        return hits\n",
    "    for path in root.rglob(\"*\"):\n",
    "        if path.is_file() and path.suffix.lower() in exts:\n",
    "            hits.append(path)\n",
    "            if len(hits) >= max_hits:\n",
    "                break\n",
    "    return hits\n",
    "\n",
    "\n",
    "def validate_raw_dataset(name: str, raw_dir: Path, strict_archives: bool = False) -> None:\n",
    "    errors = []\n",
    "    if not raw_dir.exists():\n",
    "        errors.append(\"raw dir missing\")\n",
    "    elif name == \"kaggle\":\n",
    "        kaggle_root = raw_dir / \"kaggle-dataset-6classes\"\n",
    "        if not kaggle_root.exists():\n",
    "            errors.append(\"kaggle-dataset-6classes folder missing\")\n",
    "        if not _iter_files(kaggle_root, VIDEO_EXTS):\n",
    "            errors.append(\"no videos found under kaggle-dataset-6classes\")\n",
    "    elif name == \"pskus\":\n",
    "        dataset_dirs = [p for p in raw_dir.rglob(\"DataSet*\") if p.is_dir()]\n",
    "        if not dataset_dirs:\n",
    "            errors.append(\"no DataSet* folders found\")\n",
    "        if not _iter_files(raw_dir, VIDEO_EXTS):\n",
    "            errors.append(\"no videos found\")\n",
    "        if not _iter_files(raw_dir, (\".json\",), max_hits=1):\n",
    "            errors.append(\"no annotation JSON files found\")\n",
    "        if _find_pskus_split_csv(raw_dir) is None:\n",
    "            print(\"WARNING: statistics-with-locations.csv not found; will use random split.\")\n",
    "    elif name == \"metc\":\n",
    "        interface_dirs = [p for p in raw_dir.rglob(\"Interface_number_*\") if p.is_dir()]\n",
    "        if not interface_dirs:\n",
    "            errors.append(\"no Interface_number_* folders found\")\n",
    "        if not _iter_files(raw_dir, VIDEO_EXTS):\n",
    "            errors.append(\"no videos found\")\n",
    "        if not _iter_files(raw_dir, (\".json\",), max_hits=1):\n",
    "            errors.append(\"no annotation JSON files found\")\n",
    "    elif name == \"synthetic_blender_rozakar\":\n",
    "        pngs = _iter_files(raw_dir, (\".png\",), max_hits=3)\n",
    "        if not pngs:\n",
    "            errors.append(\"no PNG files found\")\n",
    "    else:\n",
    "        errors.append(\"unknown dataset name\")\n",
    "\n",
    "    archives = _collect_archives(raw_dir)\n",
    "    if archives:\n",
    "        msg = \"archive files still present: \" + \", \".join([p.name for p in archives])\n",
    "        if strict_archives:\n",
    "            errors.append(msg)\n",
    "        else:\n",
    "            print(\"WARN:\", msg)\n",
    "\n",
    "    if errors:\n",
    "        raise RuntimeError(f\"Raw dataset validation failed for {name}: \" + \"; \".join(errors))\n",
    "\n",
    "\n",
    "def validate_processed_dataset(out_dir: Path, max_rows: int = 20) -> None:\n",
    "    errors = []\n",
    "    for split in (\"train\", \"val\", \"test\"):\n",
    "        csv_path = out_dir / f\"{split}.csv\"\n",
    "        if not csv_path.exists():\n",
    "            errors.append(f\"missing {split}.csv\")\n",
    "            continue\n",
    "        df = pd.read_csv(csv_path).head(max_rows)\n",
    "        if df.empty:\n",
    "            errors.append(f\"{split}.csv has no rows\")\n",
    "            continue\n",
    "        required = {\"frame_path\", \"class_id\", \"video_id\", \"frame_idx\"}\n",
    "        missing = required - set(df.columns)\n",
    "        if missing:\n",
    "            errors.append(f\"{split}.csv missing columns: {sorted(missing)}\")\n",
    "            continue\n",
    "        for row in df.itertuples():\n",
    "            frame_path = Path(row.frame_path)\n",
    "            if not frame_path.exists():\n",
    "                errors.append(f\"missing frame file: {frame_path}\")\n",
    "                break\n",
    "            if not (0 <= int(row.class_id) < NUM_CLASSES):\n",
    "                errors.append(f\"class_id out of range: {row.class_id}\")\n",
    "                break\n",
    "    if errors:\n",
    "        raise RuntimeError(\"Processed dataset validation failed: \" + \"; \".join(errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_slug(text: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9]+\", \"_\", text).strip(\"_\").lower()\n",
    "\n",
    "\n",
    "def _log_line(log_fp, text: str):\n",
    "    print(text)\n",
    "    if log_fp:\n",
    "        log_fp.write(text + \"\\n\")\n",
    "        log_fp.flush()\n",
    "\n",
    "\n",
    "def _dir_size_bytes(path: Path) -> int:\n",
    "    total = 0\n",
    "    if not path.exists():\n",
    "        return total\n",
    "    for p in path.rglob(\"*\"):\n",
    "        if p.is_file():\n",
    "            total += p.stat().st_size\n",
    "    return total\n",
    "\n",
    "\n",
    "def _count_files_with_ext(root: Path, exts) -> int:\n",
    "    count = 0\n",
    "    if not root.exists():\n",
    "        return count\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in exts:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def show_sample_videos(raw_dir: Path, max_videos: int = 2, log_fp=None):\n",
    "    videos = [p for p in raw_dir.rglob(\"*\") if p.suffix.lower() in VIDEO_EXTS]\n",
    "    if not videos:\n",
    "        _log_line(log_fp, \"No videos found\")\n",
    "        return\n",
    "    for vp in videos[:max_videos]:\n",
    "        _log_line(log_fp, f\"Video sample: {vp}\")\n",
    "        display(Video(str(vp), embed=True))\n",
    "\n",
    "\n",
    "def plot_class_distribution(df: pd.DataFrame, title: str, save_path: Path | None = None, show: bool = True):\n",
    "    if df.empty:\n",
    "        print(f\"No data for {title}\")\n",
    "        return\n",
    "    counts = df[\"class_id\"].value_counts().sort_index()\n",
    "    labels = [CLASS_NAMES[i] if i < len(CLASS_NAMES) else str(i) for i in counts.index]\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(x=labels, y=counts.values)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        fig.savefig(save_path, dpi=150)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "def show_samples_by_class(df: pd.DataFrame, title: str, n_per_class: int = 3,\n",
    "                          save_path: Path | None = None, show: bool = True):\n",
    "    fig = plt.figure(figsize=(3 * n_per_class, 2.5 * NUM_CLASSES))\n",
    "    idx = 1\n",
    "    for class_id in range(NUM_CLASSES):\n",
    "        subset = df[df[\"class_id\"] == class_id]\n",
    "        if subset.empty:\n",
    "            for _ in range(n_per_class):\n",
    "                plt.subplot(NUM_CLASSES, n_per_class, idx)\n",
    "                plt.text(0.5, 0.5, f\"No samples\\n{CLASS_NAMES[class_id]}\", ha=\"center\", va=\"center\")\n",
    "                plt.axis(\"off\")\n",
    "                idx += 1\n",
    "            continue\n",
    "        sample = subset.sample(min(n_per_class, len(subset)), replace=False, random_state=42)\n",
    "        for _, row in sample.iterrows():\n",
    "            img = cv2.imread(row.frame_path)\n",
    "            if img is None:\n",
    "                plt.subplot(NUM_CLASSES, n_per_class, idx)\n",
    "                plt.text(0.5, 0.5, \"missing\", ha=\"center\", va=\"center\")\n",
    "                plt.axis(\"off\")\n",
    "                idx += 1\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.subplot(NUM_CLASSES, n_per_class, idx)\n",
    "            plt.imshow(img)\n",
    "            plt.title(CLASS_NAMES[class_id], fontsize=8)\n",
    "            plt.axis(\"off\")\n",
    "            idx += 1\n",
    "        while idx % n_per_class != 1:\n",
    "            plt.subplot(NUM_CLASSES, n_per_class, idx)\n",
    "            plt.axis(\"off\")\n",
    "            idx += 1\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        fig.savefig(save_path, dpi=150)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "def log_dataframe_info(df: pd.DataFrame, label: str, log_fp=None) -> None:\n",
    "    if log_fp is None:\n",
    "        return\n",
    "    log_fp.write(f\"\\n{label} info:\\n\")\n",
    "    df.info(buf=log_fp)\n",
    "    log_fp.write(\"\\n\")\n",
    "    log_fp.write(f\"{label} describe:\\n\")\n",
    "    try:\n",
    "        log_fp.write(df.describe(include=\"all\").to_string())\n",
    "    except Exception:\n",
    "        log_fp.write(df.describe().to_string())\n",
    "    log_fp.write(\"\\n\")\n",
    "    log_fp.flush()\n",
    "\n",
    "\n",
    "def print_dataset_info(df: pd.DataFrame, label: str, log_fp=None) -> None:\n",
    "    _log_line(log_fp, f\"{label} samples: {len(df)}\")\n",
    "    if \"video_id\" in df.columns:\n",
    "        _log_line(log_fp, f\"{label} videos: {df['video_id'].nunique()}\")\n",
    "    if \"frame_idx\" in df.columns and not df.empty:\n",
    "        _log_line(log_fp, f\"{label} frame_idx range: {df['frame_idx'].min()}..{df['frame_idx'].max()}\")\n",
    "    if \"class_id\" in df.columns and not df.empty:\n",
    "        _log_line(log_fp, f\"{label} class_id range: {df['class_id'].min()}..{df['class_id'].max()}\")\n",
    "\n",
    "\n",
    "def log_dataset_sizes(raw_dir: Path, out_dir: Path, train_df: pd.DataFrame,\n",
    "                      val_df: pd.DataFrame, test_df: pd.DataFrame,\n",
    "                      log_fp=None, log_dir: Path | None = None) -> Dict:\n",
    "    combined = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "    stats = {\n",
    "        \"raw_dir\": str(raw_dir),\n",
    "        \"processed_dir\": str(out_dir),\n",
    "        \"raw_video_count\": _count_files_with_ext(raw_dir, VIDEO_EXTS),\n",
    "        \"raw_image_count\": _count_files_with_ext(raw_dir, IMAGE_EXTS),\n",
    "        \"train_rows\": int(len(train_df)),\n",
    "        \"val_rows\": int(len(val_df)),\n",
    "        \"test_rows\": int(len(test_df)),\n",
    "        \"processed_frame_count\": int(len(combined)),\n",
    "        \"processed_unique_videos\": int(combined['video_id'].nunique()) if 'video_id' in combined.columns else 0,\n",
    "    }\n",
    "    if CALCULATE_DISK_USAGE:\n",
    "        stats[\"raw_size_mb\"] = round(_dir_size_bytes(raw_dir) / (1024 * 1024), 2)\n",
    "        stats[\"processed_size_mb\"] = round(_dir_size_bytes(out_dir) / (1024 * 1024), 2)\n",
    "    _log_line(log_fp, \"Dataset size summary:\")\n",
    "    for key, value in stats.items():\n",
    "        _log_line(log_fp, f\"{key}: {value}\")\n",
    "    if log_dir is not None:\n",
    "        stats_path = log_dir / \"dataset_stats.json\"\n",
    "        with open(stats_path, \"w\") as f:\n",
    "            json.dump(stats, f, indent=2)\n",
    "    return stats\n",
    "\n",
    "\n",
    "def save_sample_frames_by_class(df: pd.DataFrame, out_dir: Path, n_per_class: int,\n",
    "                                log_fp=None) -> pd.DataFrame:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    saved_rows = []\n",
    "    for class_id in range(NUM_CLASSES):\n",
    "        subset = df[df[\"class_id\"] == class_id]\n",
    "        if subset.empty:\n",
    "            _log_line(log_fp, f\"No samples for class {class_id} ({CLASS_NAMES[class_id]})\")\n",
    "            continue\n",
    "        sample = subset.sample(min(n_per_class, len(subset)), random_state=42)\n",
    "        class_dir = out_dir / f\"{class_id}_{_safe_slug(CLASS_NAMES[class_id])}\"\n",
    "        class_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for _, row in sample.iterrows():\n",
    "            src = Path(row.frame_path)\n",
    "            if not src.exists():\n",
    "                continue\n",
    "            dst_name = f\"{row.video_id}_{int(row.frame_idx):06d}{src.suffix}\"\n",
    "            dst = class_dir / dst_name\n",
    "            try:\n",
    "                shutil.copy2(src, dst)\n",
    "            except Exception:\n",
    "                continue\n",
    "            saved_rows.append({\n",
    "                \"class_id\": int(class_id),\n",
    "                \"class_name\": CLASS_NAMES[class_id],\n",
    "                \"frame_path\": str(dst),\n",
    "                \"source_frame\": str(src),\n",
    "                \"video_id\": str(row.video_id),\n",
    "                \"frame_idx\": int(row.frame_idx),\n",
    "            })\n",
    "    return pd.DataFrame(saved_rows)\n",
    "\n",
    "\n",
    "def save_sample_videos_by_class(df: pd.DataFrame, out_dir: Path, frames_per_video: int,\n",
    "                                fps: int, log_fp=None) -> None:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for class_id in range(NUM_CLASSES):\n",
    "        subset = df[df[\"class_id\"] == class_id]\n",
    "        if subset.empty:\n",
    "            continue\n",
    "        counts = subset.groupby(\"video_id\").size().sort_values(ascending=False)\n",
    "        if counts.empty:\n",
    "            continue\n",
    "        best_video = counts.index[0]\n",
    "        frames_df = subset[subset[\"video_id\"] == best_video].sort_values(\"frame_idx\").head(frames_per_video)\n",
    "        if frames_df.empty:\n",
    "            continue\n",
    "        first = cv2.imread(frames_df.iloc[0].frame_path)\n",
    "        if first is None:\n",
    "            continue\n",
    "        height, width = first.shape[:2]\n",
    "        out_path = out_dir / f\"class_{class_id}_{_safe_slug(CLASS_NAMES[class_id])}.mp4\"\n",
    "        writer = cv2.VideoWriter(str(out_path), cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
    "        written = 0\n",
    "        for _, row in frames_df.iterrows():\n",
    "            img = cv2.imread(row.frame_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            if img.shape[:2] != (height, width):\n",
    "                img = cv2.resize(img, (width, height))\n",
    "            writer.write(img)\n",
    "            written += 1\n",
    "        writer.release()\n",
    "        if written == 0:\n",
    "            out_path.unlink(missing_ok=True)\n",
    "        else:\n",
    "            _log_line(log_fp, f\"Saved class video: {out_path} ({written} frames)\")\n",
    "\n",
    "\n",
    "def _infer_raw_label_token(path: Path) -> tuple[str | None, int | None]:\n",
    "    for part in reversed(path.parts):\n",
    "        lower = part.lower()\n",
    "        if part.isdigit():\n",
    "            val = int(part)\n",
    "            if 0 <= val < NUM_CLASSES:\n",
    "                return part, val\n",
    "        for token, idx in LABEL_TOKENS.items():\n",
    "            if token in lower:\n",
    "                return part, idx\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def collect_dataset_label_mapping(name: str, raw_dir: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    if name == \"kaggle\":\n",
    "        counts = {}\n",
    "        for path in raw_dir.rglob(\"*\"):\n",
    "            if not path.is_file():\n",
    "                continue\n",
    "            if path.suffix.lower() not in VIDEO_EXTS + IMAGE_EXTS:\n",
    "                continue\n",
    "            raw_label, mapped = _infer_raw_label_token(path)\n",
    "            if raw_label is None or mapped is None:\n",
    "                continue\n",
    "            key = (str(raw_label), int(mapped))\n",
    "            counts[key] = counts.get(key, 0) + 1\n",
    "        for (raw_label, mapped), count in sorted(counts.items(), key=lambda item: (item[0][1], item[0][0])):\n",
    "            rows.append({\n",
    "                \"dataset\": name,\n",
    "                \"raw_label\": raw_label,\n",
    "                \"mapped_class_id\": int(mapped),\n",
    "                \"class_name\": CLASS_NAMES[mapped],\n",
    "                \"count\": int(count),\n",
    "            })\n",
    "    elif name == \"pskus\":\n",
    "        for raw_label, mapped in sorted(PSKUS_CODE_MAPPING.items()):\n",
    "            rows.append({\n",
    "                \"dataset\": name,\n",
    "                \"raw_label\": str(raw_label),\n",
    "                \"mapped_class_id\": int(mapped),\n",
    "                \"class_name\": CLASS_NAMES[mapped],\n",
    "                \"count\": None,\n",
    "            })\n",
    "    elif name == \"metc\":\n",
    "        for raw_label, mapped in sorted(METC_CODE_MAPPING.items()):\n",
    "            rows.append({\n",
    "                \"dataset\": name,\n",
    "                \"raw_label\": str(raw_label),\n",
    "                \"mapped_class_id\": int(mapped),\n",
    "                \"class_name\": CLASS_NAMES[mapped],\n",
    "                \"count\": None,\n",
    "            })\n",
    "    elif name == \"synthetic_blender_rozakar\":\n",
    "        for raw_label, mapped in sorted(SYNTHETIC_GESTURE_TO_CLASS.items()):\n",
    "            rows.append({\n",
    "                \"dataset\": name,\n",
    "                \"raw_label\": str(raw_label),\n",
    "                \"mapped_class_id\": int(mapped),\n",
    "                \"class_name\": CLASS_NAMES[mapped],\n",
    "                \"count\": None,\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def summarize_class_mapping(mapping_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if mapping_df.empty:\n",
    "        return mapping_df\n",
    "    datasets = sorted(mapping_df[\"dataset\"].unique())\n",
    "    rows = []\n",
    "    for class_id, class_name in enumerate(CLASS_NAMES):\n",
    "        row = {\"class_id\": class_id, \"class_name\": class_name}\n",
    "        for ds in datasets:\n",
    "            subset = mapping_df[(mapping_df[\"dataset\"] == ds) & (mapping_df[\"mapped_class_id\"] == class_id)]\n",
    "            labels = sorted({str(v) for v in subset[\"raw_label\"].dropna().tolist()})\n",
    "            row[ds] = \", \".join(labels) if labels else \"-\"\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def show_processed_summary(train_df, val_df, test_df, dataset_name: str,\n",
    "                           log_dir: Path | None = None, log_fp=None):\n",
    "    print_dataset_info(train_df, f\"{dataset_name} train\", log_fp)\n",
    "    print_dataset_info(val_df, f\"{dataset_name} val\", log_fp)\n",
    "    print_dataset_info(test_df, f\"{dataset_name} test\", log_fp)\n",
    "\n",
    "    combined = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "    plots_dir = None\n",
    "    if log_dir is not None:\n",
    "        plots_dir = log_dir / \"plots\"\n",
    "        plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plot_class_distribution(combined, f\"{dataset_name} class distribution (all splits)\",\n",
    "                            save_path=plots_dir / \"class_distribution_all.png\" if plots_dir else None,\n",
    "                            show=True)\n",
    "    plot_class_distribution(train_df, f\"{dataset_name} class distribution (train)\",\n",
    "                            save_path=plots_dir / \"class_distribution_train.png\" if plots_dir else None,\n",
    "                            show=True)\n",
    "    plot_class_distribution(val_df, f\"{dataset_name} class distribution (val)\",\n",
    "                            save_path=plots_dir / \"class_distribution_val.png\" if plots_dir else None,\n",
    "                            show=True)\n",
    "    plot_class_distribution(test_df, f\"{dataset_name} class distribution (test)\",\n",
    "                            save_path=plots_dir / \"class_distribution_test.png\" if plots_dir else None,\n",
    "                            show=True)\n",
    "\n",
    "    counts = combined[\"class_id\"].value_counts().sort_index()\n",
    "    counts_df = pd.DataFrame({\n",
    "        \"class_id\": counts.index,\n",
    "        \"class_name\": [CLASS_NAMES[i] if i < len(CLASS_NAMES) else str(i) for i in counts.index],\n",
    "        \"count\": counts.values,\n",
    "    })\n",
    "    if log_dir is not None:\n",
    "        counts_df.to_csv(log_dir / \"class_distribution.csv\", index=False)\n",
    "\n",
    "    show_samples_by_class(combined, f\"{dataset_name} samples by class\",\n",
    "                          n_per_class=SAMPLES_PER_CLASS,\n",
    "                          save_path=plots_dir / \"samples_grid.png\" if plots_dir else None,\n",
    "                          show=True)\n",
    "\n",
    "    if SAVE_SAMPLE_MEDIA and log_dir is not None:\n",
    "        frames_dir = log_dir / \"samples\" / \"frames\"\n",
    "        videos_dir = log_dir / \"samples\" / \"videos\"\n",
    "        frames_dir.mkdir(parents=True, exist_ok=True)\n",
    "        videos_dir.mkdir(parents=True, exist_ok=True)\n",
    "        saved_df = save_sample_frames_by_class(combined, frames_dir, SAMPLES_PER_CLASS, log_fp)\n",
    "        if not saved_df.empty:\n",
    "            saved_df.to_csv(log_dir / \"samples\" / \"sample_frames.csv\", index=False)\n",
    "        save_sample_videos_by_class(combined, videos_dir, SAMPLE_VIDEO_FRAMES, SAMPLE_VIDEO_FPS, log_fp)\n",
    "\n",
    "    mapping_df = pd.DataFrame({\"class_id\": list(range(NUM_CLASSES)), \"class_name\": CLASS_NAMES})\n",
    "    _log_line(log_fp, \"Class mapping:\")\n",
    "    if log_fp:\n",
    "        log_fp.write(mapping_df.to_string(index=False) + \"\\n\")\n",
    "    if log_dir is not None:\n",
    "        mapping_df.to_csv(log_dir / \"class_mapping_canonical.csv\", index=False)\n",
    "    display(mapping_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_dataset_artifacts(name: str, raw_dir: Path, out_dir: Path, log_fp=None) -> None:\n",
    "    if not CLEANUP_BETWEEN_DATASETS:\n",
    "        return\n",
    "    _log_line(log_fp, f\"Cleaning up dataset artifacts for {name}\")\n",
    "    shutil.rmtree(raw_dir, ignore_errors=True)\n",
    "    shutil.rmtree(out_dir, ignore_errors=True)\n",
    "\n",
    "\n",
    "def process_and_validate_dataset(name: str):\n",
    "    _log_line(None, f\"\\n=== Processing {name} ===\")\n",
    "    log_dir = LOG_DIR / name if SAVE_LOGS else None\n",
    "    log_fp = None\n",
    "    raw_dir = None\n",
    "    out_dir = None\n",
    "    success = False\n",
    "\n",
    "    if log_dir is not None:\n",
    "        log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        log_fp = open(log_dir / \"validation.log\", \"w\")\n",
    "\n",
    "    try:\n",
    "        raw_dir = ensure_dataset(name)\n",
    "        if CLEANUP_ARCHIVES:\n",
    "            cleanup_archives(raw_dir, log_fp)\n",
    "        validate_raw_dataset(name, raw_dir)\n",
    "        show_sample_videos(raw_dir, max_videos=RAW_SAMPLE_VIDEOS, log_fp=log_fp)\n",
    "\n",
    "        out_dir = PROCESSED_DIR / name\n",
    "        train_csv = out_dir / \"train.csv\"\n",
    "        val_csv = out_dir / \"val.csv\"\n",
    "        test_csv = out_dir / \"test.csv\"\n",
    "        if not (train_csv.exists() and val_csv.exists() and test_csv.exists()):\n",
    "            preprocess_dataset(name)\n",
    "        validate_processed_dataset(out_dir)\n",
    "\n",
    "        train_df = pd.read_csv(train_csv)\n",
    "        val_df = pd.read_csv(val_csv)\n",
    "        test_df = pd.read_csv(test_csv)\n",
    "\n",
    "        log_dataset_sizes(raw_dir, out_dir, train_df, val_df, test_df, log_fp, log_dir)\n",
    "        log_dataframe_info(train_df, f\"{name} train\", log_fp)\n",
    "        log_dataframe_info(val_df, f\"{name} val\", log_fp)\n",
    "        log_dataframe_info(test_df, f\"{name} test\", log_fp)\n",
    "\n",
    "        show_processed_summary(train_df, val_df, test_df, name, log_dir=log_dir, log_fp=log_fp)\n",
    "\n",
    "        mapping_df = collect_dataset_label_mapping(name, raw_dir)\n",
    "        if mapping_df is not None and not mapping_df.empty:\n",
    "            if log_dir is not None:\n",
    "                mapping_df.to_csv(log_dir / \"class_mapping.csv\", index=False)\n",
    "            display(mapping_df)\n",
    "            ALL_MAPPINGS.append(mapping_df)\n",
    "        success = True\n",
    "    finally:\n",
    "        if CLEANUP_BETWEEN_DATASETS and raw_dir is not None and out_dir is not None:\n",
    "            if success or CLEANUP_ON_FAILURE:\n",
    "                cleanup_dataset_artifacts(name, raw_dir, out_dir, log_fp)\n",
    "        if log_fp is not None:\n",
    "            log_fp.close()\n",
    "\n",
    "\n",
    "for ds in DATASETS:\n",
    "    process_and_validate_dataset(ds)\n",
    "\n",
    "if ALL_MAPPINGS:\n",
    "    all_mapping_df = pd.concat(ALL_MAPPINGS, ignore_index=True)\n",
    "    summary_df = summarize_class_mapping(all_mapping_df)\n",
    "    display(summary_df)\n",
    "    if SAVE_LOGS:\n",
    "        all_mapping_df.to_csv(LOG_DIR / \"class_mapping_all.csv\", index=False)\n",
    "        summary_df.to_csv(LOG_DIR / \"class_mapping_summary.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}